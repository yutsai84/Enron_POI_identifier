{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuchengtsai/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 146 executives in this data\n",
      "there are 21 features in each evecutive\n",
      "number of labels: 95 out of 146 are workable\n",
      "number of features: 95\n",
      "[      0.  365788.  600000.]\n"
     ]
    }
   ],
   "source": [
    "features_list = ['poi','salary','bonus']\n",
    "# load the dictionary containng the dataset\n",
    "with open(\"final_project_dataset.pkl\",'r') as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "# first look at the data structure in the Enron data\n",
    "print \"there are\", len(data_dict.keys()), \"executives in this data\"\n",
    "#print data_dict.keys()\n",
    "print \"there are\", len(data_dict['METTS MARK'].keys()),\"features in each evecutive\"\n",
    "#remove outliers in the features\n",
    "# first let's check if there's any outlier in the features_list\n",
    "data_array = featureFormat(data_dict,features_list)\n",
    "labels,features = targetFeatureSplit(data_array)\n",
    "print \"number of labels:\",len(labels),\"out of\", len(data_dict.keys()),\"are workable\"\n",
    "print \"number of features:\",len(features)\n",
    "#print type(data_array)\n",
    "#print features\n",
    "print data_array[0]\n",
    "#print features[0]\n",
    "#for i in range(len(features)):\n",
    "#    salary = features[0]\n",
    "#    bonus = features[1]\n",
    "  #  plt.scatter(features[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create New Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion & Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
